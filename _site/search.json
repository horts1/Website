[
  {
    "objectID": "python/Project_Cost.html",
    "href": "python/Project_Cost.html",
    "title": "Project Cost Estimation Example",
    "section": "",
    "text": "Example of Dummy Data\n\n\nCode\nimport pandas as pd\nimport numpy as np\n\n# Create dummy data\nnp.random.seed(42)  # For reproducibility\n\ndata = {\n    'ProjectID': range(1, 101),\n    'Duration': np.random.randint(10, 50, size=100),\n    'TeamSize': np.random.randint(5, 20, size=100),\n    'Complexity': np.random.randint(1, 10, size=100),\n    'InitialBudget': np.random.randint(50, 200, size=100),\n    'PriorIssues': np.random.randint(0, 5, size=100),\n    'ProjectType': np.random.choice(['Residential', 'Commercial', 'Industrial'], size=100),\n    'TeamExperience': np.random.randint(1, 15, size=100),\n    'ExternalFactors': np.random.uniform(0.5, 1.5, size=100),\n    'ResourceAvailability': np.random.randint(1, 10, size=100),\n    'ProjectPhase': np.random.choice(['Design', 'Foundation', 'Structure', 'Finishing'], size=100),\n    'ActualCost': np.random.randint(60, 250, size=100)\n}\n\ndf = pd.DataFrame(data)\n\n# first few rows of the dataframe\ndf.head()\n\n\n\n\n\n\n\n\n\nProjectID\nDuration\nTeamSize\nComplexity\nInitialBudget\nPriorIssues\nProjectType\nTeamExperience\nExternalFactors\nResourceAvailability\nProjectPhase\nActualCost\n\n\n\n\n0\n1\n48\n11\n8\n117\n4\nCommercial\n5\n0.577735\n2\nFoundation\n121\n\n\n1\n2\n38\n11\n9\n82\n3\nCommercial\n6\n1.474395\n3\nDesign\n191\n\n\n2\n3\n24\n18\n4\n191\n4\nCommercial\n3\n1.486211\n3\nFoundation\n148\n\n\n3\n4\n17\n12\n1\n70\n3\nCommercial\n8\n1.198162\n5\nStructure\n101\n\n\n4\n5\n30\n9\n1\n97\n2\nCommercial\n13\n1.036096\n5\nStructure\n148\n\n\n\n\n\n\n\n\n\nData Prep\n\n\nCode\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# Convert categorical features to numerical values\nlabel_encoders = {}\ncategorical_features = ['ProjectType', 'ProjectPhase']\nfor feature in categorical_features:\n    le = LabelEncoder()\n    df[feature] = le.fit_transform(df[feature])\n    label_encoders[feature] = le\n\n# Split the data into features (X) and target (y)\nX = df.drop(columns=['ProjectID', 'ActualCost'])\ny = df['ActualCost']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n\n\n\nModel Training\n\n\nCode\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Initialize the RandomForestRegressor\nrf = RandomForestRegressor(random_state=42)\n\n# Train the model\nrf.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred = rf.predict(X_test)\n\n# Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\n# Output the results\nprint(\"Mean Squared Error:\", mse)\nprint(\"R^2 Score:\", r2)\n\n\nMean Squared Error: 3473.57541\nR^2 Score: -0.1123097958274566\n\n\n\n\nHyperparameter Tuning\n\n\nCode\nfrom sklearn.model_selection import GridSearchCV\n\n# Define the parameter grid\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\n\n# Initialize GridSearchCV with 3-fold cross-validation\ngrid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=0)\n\n# Fit GridSearchCV to the data\ngrid_search.fit(X_train, y_train)\n\n# Best parameters and model performance\nbest_params = grid_search.best_params_\nbest_rf = grid_search.best_estimator_\n\n# print(\"Best Parameters from GridSearchCV:\")\n# print(best_params)\n\n# Predict on the test set with the best model\ny_pred_best = best_rf.predict(X_test)\n\n# Evaluate the best model\nmse_best = mean_squared_error(y_test, y_pred_best)\nr2_best = r2_score(y_test, y_pred_best)\n\n# Output the results\nprint(\"Mean Squared Error (Best Model):\", mse_best)\nprint(\"R^2 Score (Best Model):\", r2_best)\n\n\nMean Squared Error (Best Model): 3345.293177772035\nR^2 Score (Best Model): -0.07123120483818601\n\n\n\n\nFeature Importance\n\n\nCode\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Extract feature importances from the best model\nfeature_importances = best_rf.feature_importances_\n\n# Create a DataFrame for better visualization\nfeatures_df = pd.DataFrame({\n    'Feature': X.columns,\n    'Importance': feature_importances\n})\n\n# Sort the DataFrame by importance\nfeatures_df = features_df.sort_values(by='Importance', ascending=False)\n\n# Display the feature importances\nprint(\"Feature Importances:\")\nprint(features_df)\n\n# Plotting the feature importances\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Importance', y='Feature', data=features_df, palette='viridis')\nplt.title('Feature Importances in Random Forest Model')\nplt.xlabel('Importance')\nplt.ylabel('Feature')\nplt.show()\n\n\nFeature Importances:\n                Feature  Importance\n8  ResourceAvailability    0.184655\n3         InitialBudget    0.172776\n1              TeamSize    0.156746\n0              Duration    0.111923\n7       ExternalFactors    0.105970\n6        TeamExperience    0.092655\n4           PriorIssues    0.066102\n2            Complexity    0.062543\n5           ProjectType    0.029834\n9          ProjectPhase    0.016797"
  },
  {
    "objectID": "python/Credit.html",
    "href": "python/Credit.html",
    "title": "Credit",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport os\nos.getcwd()\ndata_info = pd.read_csv(\n    'c:\\\\Users\\\\HoraceTsai\\\\Documents\\\\Jupyter\\\\TensorFlow_FILES\\DATA\\\\lending_club_info.csv',\n    index_col='LoanStatNew'\n    )\n\n\n\n\nCode\nprint(data_info.loc['revol_util']['Description'])\n\n\nRevolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.\n\n\n\n\nCode\ndef feat_info(col_name):\n    print(data_info.loc[col_name]['Description'])\n\n\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# might be needed depending on your version of Jupyter\n%matplotlib inline\n\n\n\n\nCode\ndf = pd.read_csv('c:\\\\Users\\\\HoraceTsai\\\\Documents\\\\Jupyter\\\\TensorFlow_FILES\\DATA\\\\lending_club_loan_two.csv')\n\n\n\n\nCode\ndf.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 396030 entries, 0 to 396029\nData columns (total 27 columns):\n #   Column                Non-Null Count   Dtype  \n---  ------                --------------   -----  \n 0   loan_amnt             396030 non-null  float64\n 1   term                  396030 non-null  object \n 2   int_rate              396030 non-null  float64\n 3   installment           396030 non-null  float64\n 4   grade                 396030 non-null  object \n 5   sub_grade             396030 non-null  object \n 6   emp_title             373103 non-null  object \n 7   emp_length            377729 non-null  object \n 8   home_ownership        396030 non-null  object \n 9   annual_inc            396030 non-null  float64\n 10  verification_status   396030 non-null  object \n 11  issue_d               396030 non-null  object \n 12  loan_status           396030 non-null  object \n 13  purpose               396030 non-null  object \n 14  title                 394274 non-null  object \n 15  dti                   396030 non-null  float64\n 16  earliest_cr_line      396030 non-null  object \n 17  open_acc              396030 non-null  float64\n 18  pub_rec               396030 non-null  float64\n 19  revol_bal             396030 non-null  float64\n 20  revol_util            395754 non-null  float64\n 21  total_acc             396030 non-null  float64\n 22  initial_list_status   396030 non-null  object \n 23  application_type      396030 non-null  object \n 24  mort_acc              358235 non-null  float64\n 25  pub_rec_bankruptcies  395495 non-null  float64\n 26  address               396030 non-null  object \ndtypes: float64(12), object(15)\nmemory usage: 81.6+ MB\n\n\n\nExploratory Data Analysis (EDA)\n\n\nCode\nsns.countplot(\n    x= \"loan_status\",\n    data= df)\n#inbalanced outcomes"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my professional portfolio! I am Horace Tsai, a recent graduate from California State University, Fullerton (CSUF) with a Master of Science in Statistics. In 2019, received my Bachelor of Arts in Economics with minors in Accounting and Statistics at the University of California, Irvine (UCI).\nCurrently, I am working as an Associate Program Manager, where I leverage my analytics skills and passion for data to drive projects and deliver actionable insights.\nDuring my time at CSUF, I developed a strong foundation in statistical theory, data analysis, and machine learning. My academic journey was filled with hands-on projects that honed my ability to turn complex data into clear, meaningful narratives. Whether it’s through advanced statistical modeling, data visualization, or predictive analytics, I strive to uncover patterns and insights that can drive better decision-making.\nMy professional aspiration is to transition into a full-fledged data scientist role. I am eager to apply my skills in a more focused data-centric capacity, tackling challenging problems and contributing to innovative solutions. On this website, you’ll find a showcase of my past projects, each demonstrating my proficiency in various statistical and analytical techniques, as well as my commitment to continuous learning and growth.\nFrom exploratory data analysis to building machine learning models, my projects highlight my technical expertise and my ability to translate data into strategic business value. I invite you to explore my work, and I am always open to connecting with like-minded professionals and potential collaborators.\nThank you for visiting, and I look forward to sharing my journey with you!"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "About",
    "section": "",
    "text": "Welcome to my professional portfolio! I am Horace Tsai, a recent graduate from California State University, Fullerton (CSUF) with a Master of Science in Statistics. In 2019, received my Bachelor of Arts in Economics with minors in Accounting and Statistics at the University of California, Irvine (UCI).\nCurrently, I am working as an Associate Program Manager, where I leverage my analytics skills and passion for data to drive projects and deliver actionable insights.\nDuring my time at CSUF, I developed a strong foundation in statistical theory, data analysis, and machine learning. My academic journey was filled with hands-on projects that honed my ability to turn complex data into clear, meaningful narratives. Whether it’s through advanced statistical modeling, data visualization, or predictive analytics, I strive to uncover patterns and insights that can drive better decision-making.\nMy professional aspiration is to transition into a full-fledged data scientist role. I am eager to apply my skills in a more focused data-centric capacity, tackling challenging problems and contributing to innovative solutions. On this website, you’ll find a showcase of my past projects, each demonstrating my proficiency in various statistical and analytical techniques, as well as my commitment to continuous learning and growth.\nFrom exploratory data analysis to building machine learning models, my projects highlight my technical expertise and my ability to translate data into strategic business value. I invite you to explore my work, and I am always open to connecting with like-minded professionals and potential collaborators.\nThank you for visiting, and I look forward to sharing my journey with you!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my professional portfolio! I am Horace Tsai, a recent graduate from California State University, Fullerton (CSUF) with a Master of Science in Statistics. In 2019, received my Bachelor of Arts in Economics with a double minor in Accounting and Statistics at the University of California, Irvine (UCI).\nCurrently, I am working as an Associate Program Manager, where I leverage my analytics skills and passion for data to impactfully drive projects and deliver actionable insights.\nDuring my time at CSUF, I developed a strong foundation in statistical theory, data analysis, and machine learning. My academic journey was filled with hands-on projects that honed my ability to turn complex data into clear, meaningful narratives. Whether it’s through advanced statistical modeling, data visualization, or predictive analytics, I strive to uncover patterns and insights that can drive better decision-making.\nMy professional aspiration is to transition into a full-fledged data scientist role. I am eager to apply my skills in a more focused data-centric capacity, tackling challenging problems and contributing to innovative solutions. On this website, you’ll find a showcase of my past projects, each demonstrating my proficiency in various statistical and analytical techniques, as well as my commitment to continuous learning and growth.\nFrom exploratory data analysis to building machine learning models, my projects highlight my technical expertise and my ability to translate data into strategic business value. I invite you to explore my work, and I am always open to connecting with like-minded professionals and potential collaborators.\nThank you for visiting, and I look forward to sharing my journey with you!"
  },
  {
    "objectID": "about.html#about-me",
    "href": "about.html#about-me",
    "title": "About",
    "section": "",
    "text": "Welcome to my professional portfolio! I am Horace Tsai, a recent graduate from California State University, Fullerton (CSUF) with a Master of Science in Statistics. In 2019, received my Bachelor of Arts in Economics with a double minor in Accounting and Statistics at the University of California, Irvine (UCI).\nCurrently, I am working as an Associate Program Manager, where I leverage my analytics skills and passion for data to impactfully drive projects and deliver actionable insights.\nDuring my time at CSUF, I developed a strong foundation in statistical theory, data analysis, and machine learning. My academic journey was filled with hands-on projects that honed my ability to turn complex data into clear, meaningful narratives. Whether it’s through advanced statistical modeling, data visualization, or predictive analytics, I strive to uncover patterns and insights that can drive better decision-making.\nMy professional aspiration is to transition into a full-fledged data scientist role. I am eager to apply my skills in a more focused data-centric capacity, tackling challenging problems and contributing to innovative solutions. On this website, you’ll find a showcase of my past projects, each demonstrating my proficiency in various statistical and analytical techniques, as well as my commitment to continuous learning and growth.\nFrom exploratory data analysis to building machine learning models, my projects highlight my technical expertise and my ability to translate data into strategic business value. I invite you to explore my work, and I am always open to connecting with like-minded professionals and potential collaborators.\nThank you for visiting, and I look forward to sharing my journey with you!"
  },
  {
    "objectID": "Projects.html",
    "href": "Projects.html",
    "title": "Projects",
    "section": "",
    "text": "Here are the links to some of my projects:"
  },
  {
    "objectID": "Projects.html#r-projects",
    "href": "Projects.html#r-projects",
    "title": "Projects",
    "section": "R Projects:",
    "text": "R Projects:\nInsert Links"
  },
  {
    "objectID": "Projects.html#python-projects",
    "href": "Projects.html#python-projects",
    "title": "Projects",
    "section": "Python Projects:",
    "text": "Python Projects:\nInsert Links"
  },
  {
    "objectID": "python/index.html",
    "href": "python/index.html",
    "title": "Python Projects",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis\n\n\n\n\n\nLoan Status\nProject Risk Example\nProject Cost Example"
  },
  {
    "objectID": "python/Project_Risk.html",
    "href": "python/Project_Risk.html",
    "title": "Project Risk Example",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\n\n# Create dummy data\ndata = {\n    'ProjectID': range(1, 101),\n    'Duration': np.random.randint(10, 50, size=100),\n    'Budget': np.random.randint(50, 200, size=100),\n    'TeamSize': np.random.randint(5, 20, size=100),\n    'Complexity': np.random.randint(1, 10, size=100),\n    'PriorIssues': np.random.randint(0, 5, size=100),\n    'RiskEvent': np.random.randint(0, 2, size=100)  # 0 or 1\n}\n\ndf = pd.DataFrame(data)\ndf.head()\n\n\n\n\n\n\n\n\n\nProjectID\nDuration\nBudget\nTeamSize\nComplexity\nPriorIssues\nRiskEvent\n\n\n\n\n0\n1\n45\n76\n9\n5\n3\n0\n\n\n1\n2\n22\n161\n13\n4\n4\n1\n\n\n2\n3\n19\n169\n17\n6\n0\n1\n\n\n3\n4\n29\n121\n8\n8\n1\n0\n\n\n4\n5\n17\n60\n15\n2\n0\n1"
  },
  {
    "objectID": "python/Project_Risk.html#predicting-if-there-is-going-to-be-a-risk-event-during-a-project",
    "href": "python/Project_Risk.html#predicting-if-there-is-going-to-be-a-risk-event-during-a-project",
    "title": "Project Risk Example",
    "section": "Predicting if there is going to be a Risk Event during a project:",
    "text": "Predicting if there is going to be a Risk Event during a project:\n\nLogistic Regression\n\n\nCode\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Split the data into features (X) and target (y)\nX = df[['Duration', 'Budget', 'TeamSize', 'Complexity', 'PriorIssues']]\ny = df['RiskEvent']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Initialize and train the logistic regression model\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred = model.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\n# conf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred)\n\nprint(\"Logistic Regression Accuracy is:\", format(accuracy,\".0%\"))\n\n# print(class_report)\n\n\nLogistic Regression Accuracy is: 50%\n\n\n\n\nRandom Forest\n\n\nCode\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n# Initialize and train the Random Forest model with hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\n\nrf = RandomForestClassifier(random_state=42)\ngrid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=0)\ngrid_search.fit(X_train, y_train)\n\n# Best parameters from grid search\nbest_params = grid_search.best_params_\n\n# Train the best model\nbest_rf = grid_search.best_estimator_\nbest_rf.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred = best_rf.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\n# conf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred)\n\nprint(\"Random Forest Accuracy is:\", format(accuracy,\".0%\"))\n\n# print(class_report)\n\n# best_params\n\n\nRandom Forest Accuracy is: 50%\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Extract feature importances from the best model\nfeature_importances = best_rf.feature_importances_\n\n# Create a DataFrame for better visualization\nfeatures_df = pd.DataFrame({\n    'Feature': X.columns,\n    'Importance': feature_importances\n})\n\n# Sort the DataFrame by importance\nfeatures_df = features_df.sort_values(by='Importance', ascending=False)\n\n# Display the feature importances\nprint(\"Feature Importances:\")\nprint(features_df)\n\n# Plotting the feature importances\nplt.figure(figsize=(9, 5))\nsns.barplot(x='Importance', y='Feature', data=features_df, palette='viridis')\nplt.title('Feature Importances in Random Forest Model')\nplt.xlabel('Importance')\nplt.ylabel('Feature')\nplt.show()\n\n\nFeature Importances:\n       Feature  Importance\n1       Budget    0.389014\n0     Duration    0.203648\n2     TeamSize    0.159826\n3   Complexity    0.141312\n4  PriorIssues    0.106200"
  }
]